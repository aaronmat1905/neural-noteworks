{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PreethamVJ/LangrangersFinetuningBert/blob/main/FineTuningBert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fine Tuning Bert** to Classify Medical statements \n",
    "### Note: Outputs for this notebook was not being rendered in Github. Please check: https://colab.research.google.com/drive/1YsZ9L_07gGR9WUQEoJ48WJp72eHgOMh0?usp=sharing\n",
    "- **Dataset**: https://huggingface.co/datasets/pietrolesci/pubmed-200k-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u4weDJCv6LKF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets transformers torch scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ7w8B3Y1cWI"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBAVaNb9QTCA",
    "outputId": "f581c883-00c6-45a4-b027-35a919da747e"
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBVSynNW8Ny3"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8Tm94PwQehx",
    "outputId": "a04a9d9b-1880-421e-d89d-4a2b764fc806"
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Data settings\n",
    "    'SUBSET_FRACTION': 0.6,       # Use 30% of data (0.3 = fast, 1.0 = full dataset)\n",
    "    'BALANCE_CLASSES': True,      # Handle class imbalance\n",
    "\n",
    "    # Model settings\n",
    "    'MAX_LENGTH': 128,             # Sequence length (64 = fast, 128 = better)\n",
    "    'BATCH_SIZE': 32,             # Batch size (32 = good balance)\n",
    "    'FREEZE_BERT': False,          # Freeze BERT base (True = much faster)\n",
    "\n",
    "    # Training settings\n",
    "    'LEARNING_RATE': 3e-5,        # Learning rate\n",
    "    'EPOCHS': 3,                  # Number of epochs\n",
    "    'DROPOUT': 0.3,               # Dropout rate\n",
    "\n",
    "    # Optimization\n",
    "    'USE_MIXED_PRECISION': True,  # Faster training\n",
    "    'GRADIENT_CLIPPING': 1.0,     # Gradient clipping\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liqQ3F-w8dpE"
   },
   "source": [
    "# Step 1: **Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7cgrl-d8dDw",
    "outputId": "52be2b6e-b3af-4142-9517-e93f067aed35"
   },
   "outputs": [],
   "source": [
    "# Pulling in the Dataset from HuggingFace\n",
    "dataset = load_dataset(\"pietrolesci/pubmed-200k-rct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ry1ur94LQzA0"
   },
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oGHzsvg86oV",
    "outputId": "08098869-e634-4106-d90f-c9e43bf0a45c"
   },
   "outputs": [],
   "source": [
    "report = f\"\"\"\n",
    "Train Samples: {len(dataset['train'])}\n",
    "Validation Samples: {len(dataset['validation'])}\n",
    "Test Samples: {len(dataset['test'])}\n",
    "\"\"\"\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0k-CxcMQuV5"
   },
   "outputs": [],
   "source": [
    "# Bringing the Dataset to DataFrames\n",
    "train_df = pd.DataFrame({\n",
    "    'text': dataset['train']['text'],\n",
    "    'label': dataset['train']['labels']\n",
    "})\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    'text': dataset['validation']['text'],\n",
    "    'label': dataset['validation']['labels']\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'text': dataset['test']['text'],\n",
    "    'label': dataset['test']['labels']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFepfP90RQGT",
    "outputId": "c87b9e33-29f2-4706-b994-7be17d1ef4d3"
   },
   "outputs": [],
   "source": [
    "# Using a Subset of the training data (For Faster Training)\n",
    "if CONFIG['SUBSET_FRACTION'] < 1.0:\n",
    "    print(f\"\\nUsing {CONFIG['SUBSET_FRACTION']*100}% of training data...\")\n",
    "    train_df = train_df.sample(\n",
    "        frac=CONFIG['SUBSET_FRACTION'],\n",
    "        random_state=42\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Also reduce validation/test for faster evaluation\n",
    "    val_df = val_df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
    "    test_df = test_df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(f\"  New train size: {len(train_df):,}\")\n",
    "    print(f\"  New val size: {len(val_df):,}\")\n",
    "    print(f\"  New test size: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IasIJsFa96FV"
   },
   "source": [
    "# Step 2: **EDA** (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqA_qgOURJHC"
   },
   "outputs": [],
   "source": [
    "# Class names\n",
    "label_names = ['BACKGROUND', 'CONCLUSIONS', 'METHODS','OBJECTIVE', 'RESULTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VceR-vw-Qki",
    "outputId": "fa98c492-13f1-4800-ec20-4bf93bb1f0cc"
   },
   "outputs": [],
   "source": [
    "## Analyzing Distribution of Classes\n",
    "\n",
    "# Count distribution BEFORE balancing\n",
    "original_counts = train_df['label'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nOriginal Class Distribution (before balancing):\")\n",
    "print(\"=\"*60)\n",
    "for i, name in enumerate(label_names):\n",
    "    count = original_counts[i]\n",
    "    percentage = (count / len(train_df)) * 100\n",
    "    print(f\"{name:12s}: {count:6,} ({percentage:5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_count = original_counts.max()\n",
    "min_count = original_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if imbalance_ratio > 2:\n",
    "    print(\"Significant class imbalance detected!\")\n",
    "else:\n",
    "    print(\"Classes are relatively balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "NVvd9gha-95B",
    "outputId": "9e8ba59b-caa6-4851-fdc7-6e6a0504d3ed"
   },
   "outputs": [],
   "source": [
    "# Plot original distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(\n",
    "    label_names,\n",
    "    original_counts.values,\n",
    "    color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'],\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "plt.xlabel('Class Labels', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "plt.title('Original Class Distribution (Before Balancing)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add count labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-bCnIyv_FKP",
    "outputId": "e450dfe7-8632-4dbd-f554-74cd1c9159c5"
   },
   "outputs": [],
   "source": [
    "# Balance classes using Undersampling\n",
    "if CONFIG['BALANCE_CLASSES']:\n",
    "    print(\"\\nBalancing classes using undersampling...\")\n",
    "\n",
    "    # Find minimum class size\n",
    "    min_class_size = train_df['label'].value_counts().min()\n",
    "    print(f\"  Target samples per class: {min_class_size:,}\")\n",
    "\n",
    "    # Undersample each class to minimum size\n",
    "    balanced_dfs = []\n",
    "    for label in range(5):\n",
    "        class_df = train_df[train_df['label'] == label]\n",
    "\n",
    "        # Undersample to min_class_size\n",
    "        undersampled = resample(\n",
    "            class_df,\n",
    "            replace=False,\n",
    "            n_samples=min_class_size,\n",
    "            random_state=42\n",
    "        )\n",
    "        balanced_dfs.append(undersampled)\n",
    "\n",
    "    # Combine and shuffle\n",
    "    train_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(f\"  Balanced training size: {len(train_df):,}\")\n",
    "\n",
    "    # Show new distribution\n",
    "    new_counts = train_df['label'].value_counts().sort_index()\n",
    "    print(\"\\nNew Class Distribution (after balancing):\")\n",
    "    print(\"=\"*60)\n",
    "    for i, name in enumerate(label_names):\n",
    "        count = new_counts[i]\n",
    "        percentage = (count / len(train_df)) * 100\n",
    "        print(f\"{name:12s}: {count:6,} ({percentage:5.2f}%)\")\n",
    "\n",
    "    print(\"\\nClasses balanced successfully!\")\n",
    "else:\n",
    "    print(\"\\nSkipping class balancing (CONFIG['BALANCE_CLASSES'] = False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "zrNinM_LSQaV",
    "outputId": "11136326-db78-406b-b56f-6ccccb7da5f9"
   },
   "outputs": [],
   "source": [
    "# Plot balanced distribution\n",
    "if CONFIG['BALANCE_CLASSES']:\n",
    "    balanced_counts = train_df['label'].value_counts().sort_index()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Original distribution\n",
    "    axes[0].bar(label_names, original_counts.values,\n",
    "                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'],\n",
    "                edgecolor='black', linewidth=1.5)\n",
    "    axes[0].set_title('Before Balancing', fontsize=13, fontweight='bold')\n",
    "    axes[0].set_xlabel('Class Labels', fontsize=11)\n",
    "    axes[0].set_ylabel('Number of Samples', fontsize=11)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Balanced distribution\n",
    "    axes[1].bar(label_names, balanced_counts.values,\n",
    "                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'],\n",
    "                edgecolor='black', linewidth=1.5)\n",
    "    axes[1].set_title('After Balancing', fontsize=13, fontweight='bold')\n",
    "    axes[1].set_xlabel('Class Labels', fontsize=11)\n",
    "    axes[1].set_ylabel('Number of Samples', fontsize=11)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "ZYnOgOVQ_JHy",
    "outputId": "c9045956-6fd6-4d1a-aee8-9ec498be57ee"
   },
   "outputs": [],
   "source": [
    "# Analyze text lengths\n",
    "text_lengths = [len(text.split()) for text in train_df['text']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(text_lengths, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(np.mean(text_lengths), color='red', linestyle='--',\n",
    "                linewidth=2, label=f'Mean: {np.mean(text_lengths):.1f}')\n",
    "axes[0].axvline(CONFIG['MAX_LENGTH'], color='green', linestyle='--',\n",
    "                linewidth=2, label=f'Max Length: {CONFIG[\"MAX_LENGTH\"]}')\n",
    "axes[0].set_xlabel('Number of Words', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Text Length Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(text_lengths, vert=True)\n",
    "axes[1].axhline(CONFIG['MAX_LENGTH'], color='green', linestyle='--',\n",
    "                linewidth=2, label=f'Max Length: {CONFIG[\"MAX_LENGTH\"]}')\n",
    "axes[1].set_ylabel('Number of Words', fontsize=11)\n",
    "axes[1].set_title('Text Length Box Plot', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nText Length Statistics:\")\n",
    "print(f\"  Mean: {np.mean(text_lengths):.2f} words\")\n",
    "print(f\"  Median: {np.median(text_lengths):.2f} words\")\n",
    "print(f\"  Max: {max(text_lengths)} words\")\n",
    "print(f\"  Min: {min(text_lengths)} words\")\n",
    "print(f\"  95th percentile: {np.percentile(text_lengths, 95):.2f} words\")\n",
    "\n",
    "truncated_pct = (np.array(text_lengths) > CONFIG['MAX_LENGTH']).mean() * 100\n",
    "print(f\"\\n{truncated_pct:.1f}% of texts will be truncated at MAX_LENGTH={CONFIG['MAX_LENGTH']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlhaVmvNUQOc"
   },
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset Implementation\n",
    "class PubMedDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for PubMed abstracts\"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Use __call__ instead of encode_plus (updated API)\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUdiOeKlS39w"
   },
   "source": [
    "# Step 3: **Model and Training Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMlc3FbwS62c"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT model for sequence classification.\n",
    "    Optimized for speed and performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=5, dropout=0.3):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "\n",
    "        print(\"Loading BERT model...\")\n",
    "        # Load pre-trained BERT\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        print(\"✓ BERT model loaded\")\n",
    "\n",
    "        # Dropout layer (MUST be nn.Dropout, not a float!)\n",
    "        self.dropout = nn.Dropout(p=dropout)  # ← Fixed: added nn.Dropout()\n",
    "\n",
    "        # Classification head\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "        print(\"✓ Classifier initialized\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # Get BERT outputs\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        # Use pooled output (CLS token)\n",
    "        pooled_output = outputs.pooler_output\n",
    "\n",
    "        # Apply dropout\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # Classification\n",
    "        logits = self.fc(pooled_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Koix2700ZeRU",
    "outputId": "5e046649-fcb1-4573-99af-e075841ca441"
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "print(\"Loading BERT tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating PyTorch datasets...\")\n",
    "train_dataset = PubMedDataset(\n",
    "    texts=train_df['text'].values,\n",
    "    labels=train_df['label'].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=CONFIG['MAX_LENGTH']\n",
    ")\n",
    "\n",
    "val_dataset = PubMedDataset(\n",
    "    texts=val_df['text'].values,\n",
    "    labels=val_df['label'].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=CONFIG['MAX_LENGTH']\n",
    ")\n",
    "\n",
    "test_dataset = PubMedDataset(\n",
    "    texts=test_df['text'].values,\n",
    "    labels=test_df['label'].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=CONFIG['MAX_LENGTH']\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset):,} samples\")\n",
    "print(f\"  Val: {len(val_dataset):,} samples\")\n",
    "print(f\"  Test: {len(test_dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhWcL0xSZj1p",
    "outputId": "393b2251-15eb-405d-c75d-8e7e85a3daa2"
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True  # Faster data transfer to GPU\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"DataLoader batches:\")\n",
    "print(f\"  Train: {len(train_loader)} batches\")\n",
    "print(f\"  Val: {len(val_loader)} batches\")\n",
    "print(f\"  Test: {len(test_loader)} batches\")\n",
    "\n",
    "# Estimate training time\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = steps_per_epoch * CONFIG['EPOCHS']\n",
    "print(f\"\\nTraining steps:\")\n",
    "print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"  Total steps: {total_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364,
     "referenced_widgets": [
      "566f6c6ac5364d28885a091712c8ec66",
      "e5794aca6276440680217d72d8604693",
      "8909ca9900f046379f8e5599a99c7503",
      "da4f0c001e59489f90d34e0603162d0c",
      "baf7c73056b142cf92fcf6869846fc41",
      "6f8ad9d871b04855a4de8d6b088cadc2",
      "c272ce7f2e2c4c53b47dba13799b02ef",
      "158698dd8f8949218f7351b5bd9577ea",
      "2848bb3370094e19bb0d702c235ecacd",
      "78134e87ee204ede89bd43616152b8d0",
      "55704492b9344bd1874a88bc7312a5df"
     ]
    },
    "id": "4UkxNUsUZtWZ",
    "outputId": "96b48935-f12a-4bfa-dd7d-8f03bd31b4d8"
   },
   "outputs": [],
   "source": [
    "# Initializing Model\n",
    "model = BERTClassifier(num_classes=5, dropout=CONFIG['DROPOUT'])\n",
    "model = model.to(device)\n",
    "if CONFIG['FREEZE_BERT']:\n",
    "  for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "    print(\"BERT Layers Frozen\")\n",
    "else:\n",
    "  print(\"Training All BERT Layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Fluz9t_bT3o",
    "outputId": "42252cc4-6b09-4574-a106-ab6e6e87c226"
   },
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")\n",
    "print(f\"  Frozen: {total_params - trainable_params:,}\")\n",
    "print(f\"  Reduction: {(1 - trainable_params/total_params)*100:.1f}% fewer trainable params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYSBT5LmcFhk"
   },
   "source": [
    "## Loss and Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM1Uwtq5cHTN",
    "outputId": "59e4e9b9-0d37-4a91-9192-abdf31fea447"
   },
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "print(\"\\nCalculating class weights...\")\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label'].values),\n",
    "    y=train_df['label'].values\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, name in enumerate(label_names):\n",
    "    print(f\"  {name:12s}: {class_weights[i]:.4f}\")\n",
    "\n",
    "# Loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer (only optimize trainable parameters)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=CONFIG['LEARNING_RATE'],\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Optimizer: AdamW\")\n",
    "print(f\"✓ Learning Rate: {CONFIG['LEARNING_RATE']}\")\n",
    "print(f\"✓ Loss: Weighted CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBruGn8aSUep"
   },
   "source": [
    "# Step 4: **FineTuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BImy_MnucInv"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, scaler, use_amp=True):\n",
    "    \"\"\"\n",
    "    Train model for one epoch with optional mixed precision.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_amp:\n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Mixed precision backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=CONFIG['GRADIENT_CLIPPING'])\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # Standard forward/backward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=CONFIG['GRADIENT_CLIPPING'])\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate metrics\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(predictions == labels).item()\n",
    "        total_samples += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        current_acc = correct_predictions / total_samples\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{current_acc:.4f}'\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00cLNl8PdKR6"
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZ9FquxTdD94",
    "outputId": "bd9e6747-121a-4d81-e498-5dceecd10b57"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Epochs: {CONFIG['EPOCHS']}\")\n",
    "print(f\"Batch Size: {CONFIG['BATCH_SIZE']}\")\n",
    "print(f\"Learning Rate: {CONFIG['LEARNING_RATE']}\")\n",
    "print(f\"Mixed Precision: {CONFIG['USE_MIXED_PRECISION']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Storage for metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_acc = train_model(\n",
    "        model, train_loader, criterion, optimizer, device, scaler,\n",
    "        use_amp=CONFIG['USE_MIXED_PRECISION']\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "    print(f\"  Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ✓ New best model! (Val Acc: {val_acc:.4f})\")\n",
    "\n",
    "    # Estimate remaining time\n",
    "    if epoch < CONFIG['EPOCHS'] - 1:\n",
    "        remaining_epochs = CONFIG['EPOCHS'] - epoch - 1\n",
    "        estimated_time = epoch_time * remaining_epochs\n",
    "        print(f\"  Estimated time remaining: {estimated_time/60:.1f} minutes\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Total training time\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total training time: {total_time/60:.2f} minutes\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Average time per epoch: {total_time/CONFIG['EPOCHS']:.2f}s\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5Jv2-RpPf0pC",
    "outputId": "14bd0b3f-bc56-4b08-93b2-2d66aba537f7"
   },
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs_range = range(1, CONFIG['EPOCHS'] + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, train_losses, 'bo-', label='Train Loss', linewidth=2, markersize=8)\n",
    "axes[0].plot(epochs_range, val_losses, 'ro-', label='Val Loss', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(epochs_range)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs_range, train_accuracies, 'bo-', label='Train Acc', linewidth=2, markersize=8)\n",
    "axes[1].plot(epochs_range, val_accuracies, 'ro-', label='Val Acc', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(epochs_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Epoch':<8} {'Train Loss':<12} {'Train Acc':<12} {'Val Loss':<12} {'Val Acc':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(CONFIG['EPOCHS']):\n",
    "    print(f\"{i+1:<8} {train_losses[i]:<12.4f} {train_accuracies[i]:<12.4f} \"\n",
    "          f\"{val_losses[i]:<12.4f} {val_accuracies[i]:<12.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W5Ka2u7jpgJ"
   },
   "source": [
    "# Step 5: **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4-pxAKKdCSE"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test set\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Get predictions\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Store results\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Calculate metrics\n",
    "            correct_predictions += torch.sum(predictions == labels).item()\n",
    "            total_samples += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{correct_predictions/total_samples:.4f}'\n",
    "            })\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLPmXAcuf1gi",
    "outputId": "cba161b8-43db-45c8-c56b-180756c212c3"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc, test_predictions, test_labels = evaluate_model(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Set Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQaubFOkf330",
    "outputId": "f540452f-7cfb-4cfd-b928-232b69be36ba"
   },
   "outputs": [],
   "source": [
    "# Calculate all metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    test_labels,\n",
    "    test_predictions,\n",
    "    average='weighted'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL EVALUATION METRICS (TEST SET)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f} (weighted)\")\n",
    "print(f\"Recall:    {recall:.4f} (weighted)\")\n",
    "print(f\"F1-Score:  {f1:.4f} (weighted)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssrg7Qj8f5j3",
    "outputId": "eac0cdd5-0a92-40d4-ad6c-22957af2b6d3"
   },
   "outputs": [],
   "source": [
    "# Detailed per-class metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "report = classification_report(\n",
    "    test_labels,\n",
    "    test_predictions,\n",
    "    target_names=label_names,\n",
    "    digits=4\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "Dt4-ufymf62p",
    "outputId": "e9358b14-9aa4-49ae-ec21-3d922b571bc8"
   },
   "outputs": [],
   "source": [
    "# Create and plot confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=label_names,\n",
    "    yticklabels=label_names,\n",
    "    cbar_kws={'label': 'Count'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    annot_kws={'size': 12, 'weight': 'bold'}\n",
    ")\n",
    "plt.xlabel('Predicted Label', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=13, fontweight='bold')\n",
    "plt.title('Confusion Matrix - PubMed Test Set', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.yticks(rotation=0, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze confusion matrix\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "for i, label in enumerate(label_names):\n",
    "    correct = cm[i, i]\n",
    "    total = cm[i].sum()\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    errors = total - correct\n",
    "    print(f\"{label:12s}: {correct:4d}/{total:4d} correct ({accuracy:6.2%}) | {errors:4d} errors\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfmsPCUxj7xV"
   },
   "source": [
    "# Step 6: **Inference**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZS0FrUs9iwml"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INFERENCE FUNCTION - FIXED\n",
    "# ============================================================\n",
    "\n",
    "def predict_text(text, model, tokenizer, device, label_names, max_length=128):\n",
    "    \"\"\"\n",
    "    Predict class and confidence for input text.\n",
    "\n",
    "    Args:\n",
    "        text: Input medical abstract sentence\n",
    "        model: Trained BERT model\n",
    "        tokenizer: BERT tokenizer\n",
    "        device: torch device\n",
    "        label_names: List of class names\n",
    "        max_length: Max sequence length\n",
    "\n",
    "    Returns:\n",
    "        dict with prediction results\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Handle both HuggingFace model (has .logits) and custom model (returns tensor)\n",
    "        if hasattr(outputs, 'logits'):\n",
    "            logits = outputs.logits\n",
    "        else:\n",
    "            logits = outputs  # Custom BERTClassifier returns tensor directly\n",
    "\n",
    "        probabilities = torch.softmax(logits, dim=1)[0]\n",
    "        confidence, predicted_class = torch.max(probabilities, dim=0)\n",
    "\n",
    "    predicted_label = label_names[predicted_class.item()]\n",
    "    confidence_score = confidence.item() * 100\n",
    "\n",
    "    # Get all probabilities\n",
    "    all_probs = {\n",
    "        label_names[i]: probabilities[i].item() * 100\n",
    "        for i in range(len(label_names))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'text': text,\n",
    "        'predicted': predicted_label,\n",
    "        'confidence': confidence_score,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "\n",
    "def print_prediction(result):\n",
    "    \"\"\"Pretty print prediction result\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"TEXT: {result['text'][:150]}{'...' if len(result['text']) > 150 else ''}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"PREDICTED: {result['predicted']}\")\n",
    "    print(f\"CONFIDENCE: {result['confidence']:.1f}%\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"ALL PROBABILITIES:\")\n",
    "\n",
    "    # Sort by probability\n",
    "    sorted_probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for label, prob in sorted_probs:\n",
    "        bar = '█' * int(prob / 2)\n",
    "        marker = ' <- PREDICTED' if label == result['predicted'] else ''\n",
    "        print(f\"  {label:12s}: {prob:5.1f}% {bar}{marker}\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vscWXgA24mJc",
    "outputId": "bf109d74-6694-4480-b302-9877a7edce3e"
   },
   "outputs": [],
   "source": [
    "# Testing Inference Pipeline\n",
    "# Test examples (one from each class)\n",
    "test_examples = [\n",
    "    {\n",
    "        'text': \"Previous research has demonstrated that obesity is strongly associated with type 2 diabetes and cardiovascular disease in adult populations worldwide.\",\n",
    "        'expected': 'BACKGROUND'\n",
    "    },\n",
    "    {\n",
    "        'text': \"The primary aim of this randomized controlled trial was to evaluate the efficacy and safety of a novel insulin analog in patients with poorly controlled type 2 diabetes.\",\n",
    "        'expected': 'OBJECTIVE'\n",
    "    },\n",
    "    {\n",
    "        'text': \"A total of 500 participants aged 18-65 years were randomly assigned to either the intervention group or the control group using computer-generated random numbers.\",\n",
    "        'expected': 'METHODS'\n",
    "    },\n",
    "    {\n",
    "        'text': \"The intervention group demonstrated a mean HbA1c reduction of 1.8% compared to 0.4% in the control group (p<0.001), with no significant difference in adverse events.\",\n",
    "        'expected': 'RESULTS'\n",
    "    },\n",
    "    {\n",
    "        'text': \"These findings suggest that the novel insulin analog is both effective and well-tolerated, and may represent a valuable treatment option for patients with inadequately controlled diabetes.\",\n",
    "        'expected': 'CONCLUSIONS'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "correct = 0\n",
    "total = len(test_examples)\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    print(f\"\\n{'EXAMPLE ' + str(i):.^80}\")\n",
    "    print(f\"Expected Class: {example['expected']}\\n\")\n",
    "\n",
    "    # Predict\n",
    "    result = predict_text(\n",
    "        example['text'],\n",
    "        model,\n",
    "        tokenizer,\n",
    "        device,\n",
    "        label_names,\n",
    "        max_length=CONFIG.get('MAX_LENGTH', 128)\n",
    "    )\n",
    "\n",
    "    # Print result\n",
    "    print_prediction(result)\n",
    "\n",
    "    # Check if correct\n",
    "    if result['predicted'] == example['expected']:\n",
    "        correct += 1\n",
    "        print(\"[CORRECT]\\n\")\n",
    "    else:\n",
    "        print(f\"[WRONG] Expected: {example['expected']}\\n\")\n",
    "\n",
    "# Summary\n",
    "print(f\"INFERENCE TEST SUMMARY\".center(80))\n",
    "print(f\"Correct Predictions: {correct}/{total} ({correct/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em-iWZzTayNC"
   },
   "source": [
    "# **Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq-JLH855t4B"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/PreethamVJ/LangrangersFinetuningBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahlshEtY5-3-"
   },
   "outputs": [],
   "source": [
    "path = \"/content/LangrangersFinetuningBert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUVBs2iBa3Au"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory\n",
    "models_dir = f\"{path}/saved_models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the complete model\n",
    "final_model_path = os.path.join(models_dir, \"pubmed_bert_final.pt\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': CONFIG['EPOCHS'],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'label_names': label_names,\n",
    "    'best_val_accuracy': best_val_accuracy,\n",
    "    'test_accuracy': test_acc,\n",
    "    'test_precision': precision,\n",
    "    'test_recall': recall,\n",
    "    'test_f1': f1,\n",
    "    'train_losses': train_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_losses': val_losses,\n",
    "    'val_accuracies': val_accuracies,\n",
    "}, final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg0Uu3wlbP0h",
    "outputId": "a5069e38-b622-41ce-b73f-efe6f5ea8041"
   },
   "outputs": [],
   "source": [
    "print(\"MODEL SAVED SUCCESSFULLY\")\n",
    "print(f\"Location: {final_model_path}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Also save just the model weights (smaller file)\n",
    "weights_path = os.path.join(models_dir, \"pubmed_bert_weights.pt\")\n",
    "torch.save(model.state_dict(), weights_path)\n",
    "print(f\"Weights only: {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMVruc0S6apb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "158698dd8f8949218f7351b5bd9577ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2848bb3370094e19bb0d702c235ecacd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55704492b9344bd1874a88bc7312a5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "566f6c6ac5364d28885a091712c8ec66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5794aca6276440680217d72d8604693",
       "IPY_MODEL_8909ca9900f046379f8e5599a99c7503",
       "IPY_MODEL_da4f0c001e59489f90d34e0603162d0c"
      ],
      "layout": "IPY_MODEL_baf7c73056b142cf92fcf6869846fc41"
     }
    },
    "6f8ad9d871b04855a4de8d6b088cadc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78134e87ee204ede89bd43616152b8d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8909ca9900f046379f8e5599a99c7503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_158698dd8f8949218f7351b5bd9577ea",
      "max": 199,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2848bb3370094e19bb0d702c235ecacd",
      "value": 199
     }
    },
    "baf7c73056b142cf92fcf6869846fc41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c272ce7f2e2c4c53b47dba13799b02ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da4f0c001e59489f90d34e0603162d0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78134e87ee204ede89bd43616152b8d0",
      "placeholder": "​",
      "style": "IPY_MODEL_55704492b9344bd1874a88bc7312a5df",
      "value": " 199/199 [00:00&lt;00:00, 534.20it/s, Materializing param=pooler.dense.weight]"
     }
    },
    "e5794aca6276440680217d72d8604693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f8ad9d871b04855a4de8d6b088cadc2",
      "placeholder": "​",
      "style": "IPY_MODEL_c272ce7f2e2c4c53b47dba13799b02ef",
      "value": "Loading weights: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
